<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Message Queue in Redis</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Message Queue in Redis</h1>
</header>
<section data-field="subtitle" class="p-summary">
Introduce what consideration in choosing a message queue and how to accomplish message queue in Redis.
</section>
<section data-field="body" class="e-content">
<section name="7601" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="2f9b" id="2f9b" class="graf graf--h3 graf--leading graf--title">Message Queue in Redis</h3><figure name="99bb" id="99bb" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="0*tCQ0jBqMoZYPbRem" data-width="1000" data-height="667" src="https://cdn-images-1.medium.com/max/800/0*tCQ0jBqMoZYPbRem"><figcaption class="imageCaption"><a href="https://unsplash.com/photos/sdTL4qTynfM" data-href="https://unsplash.com/photos/sdTL4qTynfM" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">Photo</a> by <a href="https://unsplash.com/@dancounsell" data-href="https://unsplash.com/@dancounsell" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">Dan Counsell</a> on Unsplash</figcaption></figure><p name="682d" id="682d" class="graf graf--p graf-after--figure">My organization has done the technical selection recently, and we want to build an event-driven system. However, the budget is limited. We cannot choose a classic queuing service like RabbitMQ or a streaming process like Kafka. We have to find an affordable solution that can meet our needs. Currently, all we have is Redis. Therefore, we will build a message queue in Redis.</p><p name="0eed" id="0eed" class="graf graf--p graf-after--p">In this article, I will introduce some properties of a message queue and describe how Redis can be used to build a message queue.</p><h3 name="8a61" id="8a61" class="graf graf--h3 graf-after--p">Message Queue</h3><p name="a480" id="a480" class="graf graf--p graf-after--h3">There are many aspects to consider when choosing a message queue, such as propagation, delivery, persistence, and consumer groups. In this section, I will explain them briefly.</p><h3 name="2901" id="2901" class="graf graf--h3 graf-after--p">Propagation</h3><p name="9907" id="9907" class="graf graf--p graf-after--h3">The propagation means how messages are transferred by the message queue. There are 2 types of propagation,</p><ul class="postList"><li name="dde9" id="dde9" class="graf graf--li graf-after--p">1-to-1</li><li name="cc75" id="cc75" class="graf graf--li graf-after--li">1-to-many (fan-out)</li></ul><p name="428e" id="428e" class="graf graf--p graf-after--li">One-to-one is quite simple. The producer sends a message to the queue, and this message is received by only one consumer. On the other hand, one-to-many is a message that can be delivered to multiple consumers. It’s worth mentioning that the producer just sent a message, but the message can be transferred to many receivers. Such behavior is also called fan-out.</p><figure name="8778" id="8778" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*J90JkLxFZDtdkrserWp-SA.png" data-width="768" data-height="700" src="https://cdn-images-1.medium.com/max/800/1*J90JkLxFZDtdkrserWp-SA.png"></figure><h3 name="aa6e" id="aa6e" class="graf graf--h3 graf-after--figure">Delivery</h3><p name="8144" id="8144" class="graf graf--p graf-after--h3">Delivery is interesting. Most queuing systems have their delivery guarantees. There are three common guarantees,</p><ul class="postList"><li name="f999" id="f999" class="graf graf--li graf-after--p">At-most-once</li><li name="b3c0" id="b3c0" class="graf graf--li graf-after--li">At-least-once</li><li name="6e76" id="6e76" class="graf graf--li graf-after--li">Exactly-once</li></ul><p name="a578" id="a578" class="graf graf--p graf-after--li">At-most-once is relatively easy to achieve. It can be said that all queuing systems have this guarantee. The consumer can receive a sent message or nothing. This may happen in several situations. Firstly, the message is lost whereas a networking problem occurred. Secondly, although the consumer received it, he did not handle it well like crashed. The message disappears if it is gone, and it is impossible to retrieve the message again.</p><p name="a7a6" id="a7a6" class="graf graf--p graf-after--p">At-least-once is a guarantee often used by some well-known systems such as RabbitMQ, Kafka, etc. Compared to at-most-once, at-least-once has a stronger guarantee. It can make sure the message must be processed. However, the message may be processed many times. For instance, a consumer does not acknowledge the queue that the message is handled, thus the queue sends a message to that consumer again.</p><p name="84ea" id="84ea" class="graf graf--p graf-after--p">Exactly-once is the strictest guarantee. It ensures the message must be handled <strong class="markup--strong markup--p-strong">once</strong>. Even the popular systems can’t do this well, e.g. RabbitMQ. Nevertheless, the correct use and configuration of Kafka can still be achieved. The price is to sacrifice some performance.</p><h3 name="807c" id="807c" class="graf graf--h3 graf-after--p">Persistence</h3><p name="0340" id="0340" class="graf graf--p graf-after--h3">Persistence means whether the message will disappear after it is sent to the system. There are also three types of persistence,</p><ul class="postList"><li name="4e44" id="4e44" class="graf graf--li graf-after--p">In-memory</li><li name="2d5b" id="2d5b" class="graf graf--li graf-after--li">In-disk</li><li name="441e" id="441e" class="graf graf--li graf-after--li">Hybrid</li></ul><p name="c916" id="c916" class="graf graf--p graf-after--li">We all know what they means. But the interesting thing is, is it slower to persist messages in disk? No, not really. It depends on how persistence is implemented. Kafka uses LSM-tree to achieve a lot of throughput; in addition, it is better than RabbitMQ who uses memory. There is another example in Cassandra, Cassandra has very fast writing speed and uses LSM-tree as well.</p><p name="6db2" id="6db2" class="graf graf--p graf-after--p">Hybrid is a special case combined with in-memory and in-disk. In order to improve the writing performance, the queuing system writes to the memory first, and then flush into the disk. RabbitMQ is a typical example in hybrid. However, RabbitMQ is also able to be configured as in-disk.</p><h3 name="c13d" id="c13d" class="graf graf--h3 graf-after--p">Consumer Group</h3><p name="e764" id="e764" class="graf graf--p graf-after--h3">In my opinion, consumer group is the most important feature in a queuing system. Processing a message usually takes time, so that we have to use more consumers to deal with messages, aka scale-out. In consumer group scenes, both the target of one-to-one and one-to-many become a group of consumers instead of a single consumer.</p><figure name="745d" id="745d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*6BPlsfNqN6AVnl-2xAW7Jg.png" data-width="1146" data-height="502" src="https://cdn-images-1.medium.com/max/800/1*6BPlsfNqN6AVnl-2xAW7Jg.png"></figure><h3 name="6d09" id="6d09" class="graf graf--h3 graf-after--figure">Redis Queue</h3><p name="d51f" id="d51f" class="graf graf--p graf-after--h3">After talking about the properties in a queuing system, let’s talk about how Redis be a message queue. There are 3 ways to do it,</p><ul class="postList"><li name="ba03" id="ba03" class="graf graf--li graf-after--p">Pub/Sub</li><li name="32b0" id="32b0" class="graf graf--li graf-after--li">List</li><li name="f221" id="f221" class="graf graf--li graf-after--li">Stream</li></ul><p name="c321" id="c321" class="graf graf--p graf-after--li">We will introduce one by one, and then give a comprehensive summary.</p><h3 name="81b3" id="81b3" class="graf graf--h3 graf-after--p">Pub/Sub</h3><figure name="6ab6" id="6ab6" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="1*C_jjZQ-aa5bXQ0bsuttziA.png" data-width="780" data-height="636" src="https://cdn-images-1.medium.com/max/800/1*C_jjZQ-aa5bXQ0bsuttziA.png"></figure><p name="88d9" id="88d9" class="graf graf--p graf-after--figure">Pub/Sub is a widely known solution for notifying, this feature was born almost at the same time as Redis. The consumer <code class="markup--code markup--p-code">SUBSCRIBE</code> a topic, aka a key, and then receive the data after a client <code class="markup--code markup--p-code">PUBLISH</code> messages to the same topic. As a traditional Pub/Sub feature, it also can fan-out a message to multiple consumers. Moreover, A certain degree of messaging routing can also be achieved through <code class="markup--code markup--p-code">PSUBSCRIBE</code>.</p><p name="98c3" id="98c3" class="graf graf--p graf-after--p">But Pub/Sub in Redis are not popular for most use cases. The biggest problem is the message will delivery at most once. When a message is published, if the consumer doesn’t receive it right now, the message disappears. Furthermore, Redis doesn’t persist messages. All messages are gone away if Redis is shutdown.</p><p name="0dca" id="0dca" class="graf graf--p graf-after--p">Let’s summarize Pub/Sub:</p><ul class="postList"><li name="0761" id="0761" class="graf graf--li graf-after--p">1-to-1 and 1-to-many are fine</li><li name="b464" id="b464" class="graf graf--li graf-after--li">at-most-once</li><li name="6258" id="6258" class="graf graf--li graf-after--li">no persistence</li><li name="bc2a" id="bc2a" class="graf graf--li graf-after--li">no consumer group</li></ul><h3 name="92ee" id="92ee" class="graf graf--h3 graf-after--li">List</h3><figure name="6064" id="6064" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="1*27N6WQ2Oas82SitCl10A8g.png" data-width="980" data-height="726" src="https://cdn-images-1.medium.com/max/800/1*27N6WQ2Oas82SitCl10A8g.png"></figure><p name="faef" id="faef" class="graf graf--p graf-after--figure">List is a useful data structure in Redis, and we can accomplish a FIFO queue easily by using it. The trick is we can use <code class="markup--code markup--p-code">BLPOP</code> to wait for a message in blocking mode. However, adding a timeout is recommended.</p><p name="70c5" id="70c5" class="graf graf--p graf-after--p">According to the figure, we can see if there are multiple consumers wait for the same list, they are becoming a consumer group. Without configuring anything, the consumer group can be spontaneously formed by consumers. On the other hand, list cannot fan-out a message. If a message is <code class="markup--code markup--p-code">BLPOP</code> by a consumer, others can not be retrieved this message anymore, even the message is lost in that consumer.</p><p name="c5c5" id="c5c5" class="graf graf--p graf-after--p">Nevertheless, Redis list can persist messages in memory. In addition, if you are enabling <code class="markup--code markup--p-code">AOF</code> or <code class="markup--code markup--p-code">RDB</code>, messages can be backed up into the disk. I have to say, following <a href="https://lazypro.medium.com/data-persistence-in-redis-2780c11d1623" data-href="https://lazypro.medium.com/data-persistence-in-redis-2780c11d1623" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">my previous article</a>, this approach is not entirely data persistence.</p><p name="ffb2" id="ffb2" class="graf graf--p graf-after--p">To sum up,</p><ul class="postList"><li name="82a4" id="82a4" class="graf graf--li graf-after--p">1-to-1 is okay, but no 1-to-many</li><li name="874d" id="874d" class="graf graf--li graf-after--li">at-most-once</li><li name="2bd8" id="2bd8" class="graf graf--li graf-after--li">persist in-memory, and backup in-disk</li><li name="4627" id="4627" class="graf graf--li graf-after--li">consumer group works</li></ul><h3 name="86be" id="86be" class="graf graf--h3 graf-after--li">Stream</h3><p name="75d2" id="75d2" class="graf graf--p graf-after--h3">After introducing the Pub/Sub and List, we notice that neither of these two methods is very good. They have their own drawbacks. Therefore, Stream has come to solve these issues since Redis 5.0.</p><p name="1444" id="1444" class="graf graf--p graf-after--p">Because Stream is much more complicated, let’s first look at what benefits Stream brings.</p><ul class="postList"><li name="12ec" id="12ec" class="graf graf--li graf-after--p">1-to-1 and 1-to-many are fine</li><li name="0534" id="0534" class="graf graf--li graf-after--li">at-least-once</li><li name="da68" id="da68" class="graf graf--li graf-after--li">persist in-memory, and backup in-disk</li><li name="d473" id="d473" class="graf graf--li graf-after--li">consumer group works</li></ul><p name="0ab7" id="0ab7" class="graf graf--p graf-after--li">As a result, Stream solves all issues in Pub/Sub and List and enhances a lot, for e.g., at-least-once delivery.</p><figure name="2a7d" id="2a7d" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*UTwE0z5imsbukNG_mEnSvw.png" data-width="1128" data-height="656" src="https://cdn-images-1.medium.com/max/800/1*UTwE0z5imsbukNG_mEnSvw.png"></figure><p name="2f52" id="2f52" class="graf graf--p graf-after--figure">The diagram is like Pub/Sub, but the workflow is closer to List. The producer can generate messages at any time, and then <code class="markup--code markup--p-code">XADD</code> to Redis Stream. You can consider Stream as a list maintains all incoming messages. Consumers can also retrieve messages at any time via <code class="markup--code markup--p-code">XREAD</code>. The identifier in <code class="markup--code markup--p-code">XREAD</code> command represents where you want to read the message from.</p><ul class="postList"><li name="faa1" id="faa1" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code">$</code>: No matter what messages are in Stream before, only retrieve from now on.</li><li name="2235" id="2235" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">0-0</code>: Always read from the head.</li><li name="4f84" id="4f84" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">&lt;id&gt;</code>: Start from the specific message id.</li></ul><p name="65b8" id="65b8" class="graf graf--p graf-after--li">Apart from supporting one-to-one mapping, Stream supports consumer groups as follows:</p><figure name="d746" id="d746" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*IOg5-gQnDynx8HjDe7YuRg.png" data-width="852" data-height="656" src="https://cdn-images-1.medium.com/max/800/1*IOg5-gQnDynx8HjDe7YuRg.png"></figure><p name="01c5" id="01c5" class="graf graf--p graf-after--figure">To achieve at-least-once guarantee, like most queuing systems, the consumer must acknowledge Stream after processing a message by using <code class="markup--code markup--p-code">XACK</code>.</p><p name="3ceb" id="3ceb" class="graf graf--p graf-after--p">The use of the special identifier, <code class="markup--code markup--p-code">&lt;</code>, here is to start reading from a position that no one has read in the group.</p><p name="e143" id="e143" class="graf graf--p graf-after--p">After the above explanation, I provide a real example to show a consumer’s bootstrap in Node.js.</p><figure name="a259" id="a259" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/wirelessr/b88561af2fe629bb94fe0a6cc4410af8.js"></script></figure><p name="67da" id="67da" class="graf graf--p graf-after--figure">Please note that every consumer has his own name, <code class="markup--code markup--p-code">ConsumerName</code>. First, the consumer read from the beginning to determine its last position. The response will be a empty array with no length, so that the consumer can get the correct <code class="markup--code markup--p-code">lastid</code>. Then, the consumer reads from the <code class="markup--code markup--p-code">lastid</code> and processes those messages. Finally, acknowledge Stream with finished <code class="markup--code markup--p-code">id</code>.</p><h3 name="18a8" id="18a8" class="graf graf--h3 graf-after--p">Stream Consumer Failover</h3><p name="f271" id="f271" class="graf graf--p graf-after--h3">In the distributed system, we cannot name a consumer easily. For example, the consumer is run in a container within K8s: How do I maintain names to every pod? Even if we lock everyone’s name, how do we face the scale-out and scale-in scene?</p><p name="4476" id="4476" class="graf graf--p graf-after--p">Therefore, keeping the name in the distributed system is impractical.</p><p name="ebb1" id="ebb1" class="graf graf--p graf-after--p">In spite of this, we cannot name a consumer in <code class="markup--code markup--p-code">uuid</code> and forget the name after the consumer is down. Redis Stream maintains a table of names against last positions. So, if we generate a random name every time, the mapping table will become larger and larger. Worst of all, those messages that have been received but not acknowledged will never be processed.</p><p name="5ef7" id="5ef7" class="graf graf--p graf-after--p">Fortunately, Redis Stream provides a method to claim those pending messages. The workflow is like this:</p><ol class="postList"><li name="12ae" id="12ae" class="graf graf--li graf-after--p">Find out all pending message ids.</li><li name="f969" id="f969" class="graf graf--li graf-after--li">Claim those ids to transfer the ownership.</li></ol><p name="8095" id="8095" class="graf graf--p graf-after--li">Therefore, the completed workflow in a consumer bootstrap is:</p><ol class="postList"><li name="b50d" id="b50d" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code">XPENDING StreamName GroupName</code></li><li name="df36" id="df36" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">XCLAIM StreamName GroupName &lt;ConsumerName in uuid&gt; &lt;min-idle-time&gt; &lt;ID-1&gt; &lt;ID-2&gt; ... &lt;ID-N&gt;</code></li><li name="7735" id="7735" class="graf graf--li graf-after--li">The above script</li></ol><p name="6fff" id="6fff" class="graf graf--p graf-after--li">The <code class="markup--code markup--p-code">min-idle-time</code> is a very useful approach. By using <code class="markup--code markup--p-code">min-idle-time</code>, we can avoid multiple consumers claim the same messages at the same time. The first consumer claims some messages, so such messages will no longer be idle. Hence, other consumers cannot claim those messages again.</p><h3 name="fe34" id="fe34" class="graf graf--h3 graf-after--p">Redis Stream Persistence</h3><p name="bc05" id="bc05" class="graf graf--p graf-after--h3">Redis does not guarantee that the data will not be lost at all, even if the strictest setting is turned on. If we use Redis as a message queue, we must take additional measures to ensure persistence. The most common way is event-sourcing. Before publishing a message, we write this message into a durable storage like MySQL. Our consumers can work generally. However, if an error occurs, we can still leverage the durable messages in MySQL to recover our work.</p><p name="2dcf" id="2dcf" class="graf graf--p graf-after--p">Besides, if Stream persists more and more messages, the memory usage of Redis would be a disaster. If we are looking at the Redis manual, we can find a command, <code class="markup--code markup--p-code">XDEL</code>. However, <code class="markup--code markup--p-code">XDEL</code> does not delete the messages, it only marks those messages as unused, and the messages are still there.</p><p name="f330" id="f330" class="graf graf--p graf-after--p">How can we prevent memory leakage in Redis Stream? We can use <code class="markup--code markup--p-code">MAXLEN</code> whereas <code class="markup--code markup--p-code">XADD</code> is invoking. The command line is:</p><blockquote name="41b9" id="41b9" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">XADD StreamName MAXLEN 1000 * foo bar</em></blockquote><p name="3b24" id="3b24" class="graf graf--p graf-after--blockquote">But there is one thing you have to know, <code class="markup--code markup--p-code">MAXLEN</code> affects performance of Redis very much. It blocks the main process for a while, and no command can be executed during that period. If there are many incoming messages and the amount of queued messages reaches maximum, then Stream will be very busy to maintain <code class="markup--code markup--p-code">MAXLEN</code>.</p><p name="6fe5" id="6fe5" class="graf graf--p graf-after--p">An alternative approach can be adopted. Instead of fixing the hard limit, we can give Redis the right to choose a comfortable length at its free time. Hence, the command will be:</p><blockquote name="f091" id="f091" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">XADD StreamName MAXLEN ~ 1000 * foo bar</em></blockquote><p name="3014" id="3014" class="graf graf--p graf-after--blockquote">The <code class="markup--code markup--p-code">~</code> sign means the maximum length is about 1000, it might be 900 or even 1300. Redis will pick a good time to strip a good size for it.</p><h3 name="e9a8" id="e9a8" class="graf graf--h3 graf-after--p">Conclusion</h3><p name="861f" id="861f" class="graf graf--p graf-after--h3">Let me summarize these three approaches.</p><figure name="4baa" id="4baa" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*o68_P7KksDT9gt13nouN_g.png" data-width="1062" data-height="486" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*o68_P7KksDT9gt13nouN_g.png"></figure><p name="d5e0" id="d5e0" class="graf graf--p graf-after--figure">There is an unfamiliar property complexity, which refers to the complexity of a technology but also the complexity of implementing a consumer.</p><p name="9331" id="9331" class="graf graf--p graf-after--p">From my point of view, these three approaches have their pros and cons and also have their own applicable scenarios.</p><ul class="postList"><li name="ecaa" id="ecaa" class="graf graf--li graf-after--p">Pub/Sub: Best-effort notification.</li><li name="9e7e" id="9e7e" class="graf graf--li graf-after--li">List: Tolerate message queues with some data loss.</li><li name="d906" id="d906" class="graf graf--li graf-after--li">Stream: Loose streaming process.</li></ul><p name="3ae4" id="3ae4" class="graf graf--p graf-after--li">So, why is Redis Stream a loose streaming process? Because the consumer group in Redis Stream is not like Kafka. It cannot preserve the message ordering. In a high-volume traffic environment, consumers within the same group cannot be scaled out successfully.</p><p name="cf14" id="cf14" class="graf graf--p graf-after--p graf--trailing">In the end, we chose List as the message queue. Our use cases are simple. We just want to throttle the notifications in the broadcast scene. The broadcast notification can tolerate the message loss. It’s good enough that most users can receive the message. In addition, the implementation effort is very low in Node.js, so we can finish it as soon as possible. Although it is not the best solution, it is good enough for our organization.</p></div></div></section><section name="9fbf" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h4 name="0a70" id="0a70" class="graf graf--h4 graf--leading">The world’s fastest cloud data warehouse:</h4><p name="ff72" id="ff72" class="graf graf--p graf-after--h4 graf--trailing">When designing analytics experiences which are consumed by customers in production, even the smallest delays in query response times become critical. Learn how to achieve <strong class="markup--strong markup--p-strong">sub-second</strong> performance over TBs of data with <a href="https://www.firebolt.io/?v=m" data-href="https://www.firebolt.io/?v=m" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">Firebolt</strong>.</a></p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@lazypro" class="p-author h-card">Chunting Wu</a> on <a href="https://medium.com/p/9efe0de2c39c"><time class="dt-published" datetime="2021-11-18T13:29:56.726Z">November 18, 2021</time></a>.</p><p><a href="https://medium.com/@lazypro/message-queue-in-redis-9efe0de2c39c" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on October 21, 2024.</p></footer></article></body></html>