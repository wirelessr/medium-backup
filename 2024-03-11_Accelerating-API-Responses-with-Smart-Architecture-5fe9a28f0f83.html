<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Accelerating API Responses with Smart Architecture</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Accelerating API Responses with Smart Architecture</h1>
</header>
<section data-field="subtitle" class="p-summary">
Experience a boost in API response times with our paradigm-shifting move from Semi-Lambda to TiDB &amp; Kappa architecture
</section>
<section data-field="body" class="e-content">
<section name="7e4d" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="6c70" id="6c70" class="graf graf--h3 graf--leading graf--title">Accelerating API Responses with Smart Architecture</h3><h4 name="f61b" id="f61b" class="graf graf--h4 graf-after--h3 graf--subtitle">Experience a boost in API response times with our paradigm-shifting move from Semi-Lambda to TiDB &amp; Kappa architecture</h4><figure name="2d1f" id="2d1f" class="graf graf--figure graf-after--h4"><img class="graf-image" data-image-id="0*IhK9f60eYRXLUfNL" data-width="1000" data-height="667" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/0*IhK9f60eYRXLUfNL"><figcaption class="imageCaption">Photo by <a href="https://unsplash.com/@markusspiske" data-href="https://unsplash.com/@markusspiske" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">Markus Spiske</a> on <a href="https://unsplash.com/photos/matrix-movie-still-iar-afB0QQw" data-href="https://unsplash.com/photos/matrix-movie-still-iar-afB0QQw" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">Unsplash</a></figcaption></figure><p name="c59b" id="c59b" class="graf graf--p graf-after--figure">We recently launched a big technical revamp, and the results have been impressive. We’ve seen a 9x improvement in response times for specific APIs (from 9 seconds down to 1 second).</p><p name="46e1" id="46e1" class="graf graf--p graf-after--p">You may ask why the API response time is so long. It’s mainly because of the product characteristics, it’s a data product, there will be a lot of data aggregation and analysis, and the API response will be the result of a period of analysis. Therefore, in general, there will be a longer latency.</p><p name="8d2f" id="8d2f" class="graf graf--p graf-after--p">Nevertheless, through this technical revamp, we have significantly reduced the API latency while maintaining the product features.</p><p name="803b" id="803b" class="graf graf--p graf-after--p">This is due to two core changes.</p><ol class="postList"><li name="2d35" id="2d35" class="graf graf--li graf-after--p">Database changes</li><li name="065a" id="065a" class="graf graf--li graf-after--li">Kappa architecture</li></ol><p name="6452" id="6452" class="graf graf--p graf-after--li">Let’s take a closer look at what we did.</p><h3 name="075e" id="075e" class="graf graf--h3 graf-after--p">Semi-Lambda Architecture</h3><p name="7b50" id="7b50" class="graf graf--p graf-after--h3">At first, our architecture is a “semi-Lambda” architecture. To understand what a semi-Lambda architecture is, let’s first look at a Lambda architecture.</p><p name="4b2c" id="4b2c" class="graf graf--p graf-after--p">A <a href="https://en.wikipedia.org/wiki/Lambda_architecture" data-href="https://en.wikipedia.org/wiki/Lambda_architecture" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">typical Lambda architecture</a> has three components.</p><ol class="postList"><li name="1fde" id="1fde" class="graf graf--li graf-after--p">Batch layer</li><li name="e226" id="e226" class="graf graf--li graf-after--li">Speed layer</li><li name="ac13" id="ac13" class="graf graf--li graf-after--li">Serving layer</li></ol><figure name="8a2f" id="8a2f" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*_kpuP6tt0HDMdETQ9Ia12A.png" data-width="1090" data-height="502" src="https://cdn-images-1.medium.com/max/800/1*_kpuP6tt0HDMdETQ9Ia12A.png"></figure><p name="dae6" id="dae6" class="graf graf--p graf-after--figure">Data processing from the data source is divided into two paths, one is periodic batch processing, which has the advantage of processing a large amount of data quickly.</p><p name="7c2e" id="7c2e" class="graf graf--p graf-after--p">On the other hand, in order to enhance the freshness of the analysis, there is real-time processing to calculate the data in the current time period. The results from both sides are aggregated into a serving layer so that end users can get the final results.</p><p name="3115" id="3115" class="graf graf--p graf-after--p">For example, if the time is 12:30 and the batch layer runs every full hour, then the data from 12:01 to 12:30 will be processed by the speed layer.</p><p name="a8ec" id="a8ec" class="graf graf--p graf-after--p">The above is a standard Lambda architecture.</p><p name="b4e0" id="b4e0" class="graf graf--p graf-after--p">Then, what is a semi-Lambda architecture? The illustration is as follows.</p><figure name="d9ac" id="d9ac" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*ZDyYOvNn7QAEyA--dQBfug.png" data-width="1154" data-height="374" src="https://cdn-images-1.medium.com/max/800/1*ZDyYOvNn7QAEyA--dQBfug.png"></figure><p name="0cdf" id="0cdf" class="graf graf--p graf-after--figure">We also have a batch layer and a serving layer, but we are missing the speed layer. Instead, we write the raw data directly into the serving layer, and the client, e.g. API, which is invoked by the upper layer, runs the logic to process the raw data and combine it with the batch result.</p><p name="a143" id="a143" class="graf graf--p graf-after--p">In other words, we are the on-the-fly speed layer.</p><p name="e1ac" id="e1ac" class="graf graf--p graf-after--p">The drawbacks of such an architecture are obvious.</p><ol class="postList"><li name="f0b4" id="f0b4" class="graf graf--li graf-after--p">Postgres is a monolithic database, so even though it can be read-write split, the replicas still need to synchronize with the master constantly. This is fatal in large raw data write scenarios, where I/O consumes a lot of system resources.</li><li name="dbed" id="dbed" class="graf graf--li graf-after--li">Postgres is limited in its capability to handle big data. Although it is possible to make data blocks smaller and easier to read by partitioning, a single database is not enough when the algorithm is designed for a large number of partitions.</li></ol><p name="958c" id="958c" class="graf graf--p graf-after--li">Therefore, we need to propose solutions to these two problems.</p><h3 name="4893" id="4893" class="graf graf--h3 graf-after--p">Streaming ingest problem</h3><p name="aa0c" id="aa0c" class="graf graf--p graf-after--h3">First of all, we need to solve the database bottleneck of writing large amounts of data. Therefore, a proper database is essential.</p><p name="219a" id="219a" class="graf graf--p graf-after--p">For those who have been following me, you should know I have been studying RTOLAP databases such as <a href="https://medium.com/dev-genius/building-apache-pinot-and-presto-bf91388c7df5" data-href="https://medium.com/dev-genius/building-apache-pinot-and-presto-bf91388c7df5" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Apache Pinot</a> for some time. But in the end, we didn’t go with RTOLAP.</p><p name="8cdd" id="8cdd" class="graf graf--p graf-after--p">The main reason is RTOLAP database does not perform well in two specific scenarios.</p><ol class="postList"><li name="f61c" id="f61c" class="graf graf--li graf-after--p">Upsert</li><li name="66ee" id="66ee" class="graf graf--li graf-after--li">Join</li></ol><p name="2e9c" id="2e9c" class="graf graf--p graf-after--li">Because of the application features, we need to perform frequent upserts on big data, and in addition, we need to do a large number of joins, doesn’t matter if it’s a cross-table join or self-table join.</p><p name="3aa9" id="3aa9" class="graf graf--p graf-after--p">On the other hand, it is difficult to say RTOLAP database has comprehensive support for SQL statements, and we want to minimize the amount of trial-and-error work required for migration, so we didn’t choose RTOLAP database in the end.</p><p name="2ac0" id="2ac0" class="graf graf--p graf-after--p">Fortunately, around the same time, we got some help from a vendor and learned about a distributed database completely compatible with MySQL, i.e. TiDB. Previously, <a href="https://medium.com/@lazypro/htap-learning-from-xiaohongshu-8d8181d12195" data-href="https://medium.com/@lazypro/htap-learning-from-xiaohongshu-8d8181d12195" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">I wrote an article</a> describing TiDB application scenarios. In fact, TiDB can support both OLTP and OLAP scenarios, fitting our needs.</p><h3 name="1e94" id="1e94" class="graf graf--h3 graf-after--p">Speed layer problem</h3><p name="dcae" id="dcae" class="graf graf--p graf-after--h3">Once the database selection is finalized, the next step is to address the lack of a complete speed layer.</p><p name="28ef" id="28ef" class="graf graf--p graf-after--p">There are two possible directions.</p><ol class="postList"><li name="dfe4" id="dfe4" class="graf graf--li graf-after--p">Build a complete Lambda speed layer.</li><li name="b488" id="b488" class="graf graf--li graf-after--li">Change to Kappa architecture</li></ol><p name="bad6" id="bad6" class="graf graf--p graf-after--li">In the end, we chose the latter and started to move the architecture to Kappa.</p><p name="597d" id="597d" class="graf graf--p graf-after--p">The reason is both Lambda and Kappa need to build streaming processing capabilities, but to build a speed layer for the Lambda architecture we still need to rewrite the batch logic in a streaming framework. It would be better to migrate the batch logic to the Kappa framework so that if there is a need for any feature in the future, we just need to add the new logic to the streaming framework.</p><p name="2ed0" id="2ed0" class="graf graf--p graf-after--p">This is one of the advantages of Kappa over Lambda, there is no need to maintain two pipelines (batch and real-time) with the same logic.</p><figure name="051e" id="051e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Smd9TkUWEXNFAViOAbsuyw.png" data-width="1154" data-height="222" src="https://cdn-images-1.medium.com/max/800/1*Smd9TkUWEXNFAViOAbsuyw.png"></figure><p name="f892" id="f892" class="graf graf--p graf-after--figure">After moving to the Kappa paradigm, you can see that the whole architecture has become simple, with Flink being responsible for data processing and batch processing disappearing. In addition, Postgres was moved to TiDB, which of course required changes to the query syntax, but it was well worth it.</p><p name="d859" id="d859" class="graf graf--p graf-after--p">Finally, we solved the OLAP query latency problem by using streaming pre-processing and the power of the TiDB distributed database.</p><h3 name="89fc" id="89fc" class="graf graf--h3 graf-after--p">Conclusion</h3><p name="c2d0" id="c2d0" class="graf graf--p graf-after--h3">Paradigm shift is a battle against time, and how to keep optimizing the system while guaranteeing development productivity is a big challenge.</p><p name="73f6" id="73f6" class="graf graf--p graf-after--p">In addition to initiating discussions and a series of technical selections, it is more important to plan the actual migration and develop efficiently. This requires architects, PMs, and developers to work together.</p><p name="a0c1" id="a0c1" class="graf graf--p graf-after--p">The question is frequently asked: How much of a benefit is this migration? It’s a tough question to answer before getting one’s hands dirty. But if we don’t know the benefits, how can we have the confidence to invest for such a long period of time?</p><p name="816c" id="816c" class="graf graf--p graf-after--p">From my point of view, we need to list the problems we want to solve and prioritize them in a way that will affect the final solution. Then, identify one or two showcases to act as pilots, and learn as much as possible from these showcases, rather than launching a large-scale revamp all at once.</p><p name="ffdd" id="ffdd" class="graf graf--p graf-after--p">When results are achieved in the showcases, we will be able to measure the benefits.</p><p name="d696" id="d696" class="graf graf--p graf-after--p">Engineering is different from science in nature. Engineering is learning by doing, not by theorizing. Airplanes fly before scientific theories can explain them, that’s my mindset on technical revamping, let’s see what you guys think too.</p><h3 name="933c" id="933c" class="graf graf--h3 graf-after--p">Stackademic 🎓</h3><p name="0fe9" id="0fe9" class="graf graf--p graf-after--h3">Thank you for reading until the end. Before you go:</p><ul class="postList"><li name="1427" id="1427" class="graf graf--li graf-after--p">Please consider <strong class="markup--strong markup--li-strong">clapping</strong> and <strong class="markup--strong markup--li-strong">following</strong> the writer! 👏</li><li name="2598" id="2598" class="graf graf--li graf-after--li">Follow us <a href="https://twitter.com/stackademichq" data-href="https://twitter.com/stackademichq" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--li-strong">X</strong></a><strong class="markup--strong markup--li-strong"> | </strong><a href="https://www.linkedin.com/company/stackademic" data-href="https://www.linkedin.com/company/stackademic" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--li-strong">LinkedIn</strong></a><strong class="markup--strong markup--li-strong"> | </strong><a href="https://www.youtube.com/c/stackademic" data-href="https://www.youtube.com/c/stackademic" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--li-strong">YouTube</strong></a><strong class="markup--strong markup--li-strong"> | </strong><a href="https://discord.gg/in-plain-english-709094664682340443" data-href="https://discord.gg/in-plain-english-709094664682340443" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--li-strong">Discord</strong></a></li><li name="e549" id="e549" class="graf graf--li graf-after--li">Visit our other platforms: <a href="https://plainenglish.io" data-href="https://plainenglish.io" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--li-strong">In Plain English</strong></a><strong class="markup--strong markup--li-strong"> | </strong><a href="https://cofeed.app/" data-href="https://cofeed.app/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--li-strong">CoFeed</strong></a><strong class="markup--strong markup--li-strong"> | </strong><a href="https://venturemagazine.net/" data-href="https://venturemagazine.net/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--li-strong">Venture</strong></a><strong class="markup--strong markup--li-strong"> | </strong><a href="https://blog.cubed.run" data-href="https://blog.cubed.run" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--li-strong">Cubed</strong></a></li><li name="2051" id="2051" class="graf graf--li graf-after--li graf--trailing">More content at <a href="https://stackademic.com" data-href="https://stackademic.com" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--li-strong">Stackademic.com</strong></a></li></ul></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@lazypro" class="p-author h-card">Chunting Wu</a> on <a href="https://medium.com/p/5fe9a28f0f83"><time class="dt-published" datetime="2024-03-11T01:46:20.676Z">March 11, 2024</time></a>.</p><p><a href="https://medium.com/@lazypro/tidb-kappa-accelerating-api-responses-with-smart-architecture-5fe9a28f0f83" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on October 21, 2024.</p></footer></article></body></html>