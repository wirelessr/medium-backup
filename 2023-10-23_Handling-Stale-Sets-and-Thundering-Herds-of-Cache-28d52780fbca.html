<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Handling Stale Sets and Thundering Herds of Cache</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Handling Stale Sets and Thundering Herds of Cache</h1>
</header>
<section data-field="subtitle" class="p-summary">
Simplified Approach Inspired by Facebook’s Innovative Solution
</section>
<section data-field="body" class="e-content">
<section name="9030" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="dae6" id="dae6" class="graf graf--h3 graf--leading graf--title">Handling Stale Sets and Thundering Herds of Cache</h3><h4 name="bbe8" id="bbe8" class="graf graf--h4 graf-after--h3 graf--subtitle">Simplified Approach Inspired by Facebook’s Innovative Solution</h4><figure name="aab1" id="aab1" class="graf graf--figure graf-after--h4"><img class="graf-image" data-image-id="0*sGFeNnBV2GtxJrGO" data-width="1000" data-height="750" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/0*sGFeNnBV2GtxJrGO"><figcaption class="imageCaption">Photo by <a href="https://unsplash.com/@alexbemore" data-href="https://unsplash.com/@alexbemore" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">Alexander Shatov</a> on <a href="https://unsplash.com/photos/blue-and-white-star-illustration-CTZhGbSxWLI" data-href="https://unsplash.com/photos/blue-and-white-star-illustration-CTZhGbSxWLI" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">Unsplash</a></figcaption></figure><p name="8a2c" id="8a2c" class="graf graf--p graf-after--figure">Recently, I’ve been studying how Facebook handles <a href="https://research.facebook.com/publications/scaling-memcache-at-facebook/" data-href="https://research.facebook.com/publications/scaling-memcache-at-facebook/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">caching at scale</a>, and one of the subsections describes how they handle stale sets and thundering herds. They use a lease mechanism to face these two problems at once, which is very interesting.</p><p name="0b16" id="0b16" class="graf graf--p graf-after--p">What are stale sets and thundering herds? Let me explain each in one simple sentence.</p><ul class="postList"><li name="ba2d" id="ba2d" class="graf graf--li graf-after--p">Stale sets: Data inconsistency between cache and database.</li><li name="9c3f" id="9c3f" class="graf graf--li graf-after--li">Thundering herds (aka Dogpile effect): High concurrency request to knock down the database.</li></ul><p name="f524" id="f524" class="graf graf--p graf-after--li">In fact, I have also introduced how to solve the problem of stale sets and thundering herds, only that I have proposed my own solutions to each problem, and I do not have a one-size-fits-all solution.</p><ul class="postList"><li name="75e9" id="75e9" class="graf graf--li graf-after--p"><a href="https://lazypro.medium.com/consistency-between-cache-and-database-part-1-f64f4a76720" data-href="https://lazypro.medium.com/consistency-between-cache-and-database-part-1-f64f4a76720" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Solving stale sets</a></li><li name="376a" id="376a" class="graf graf--li graf-after--li"><a href="https://medium.com/@lazypro/solving-dogpile-effect-9d869174d302" data-href="https://medium.com/@lazypro/solving-dogpile-effect-9d869174d302" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Solving thundering herds</a></li></ul><p name="8c59" id="8c59" class="graf graf--p graf-after--li">Let’s take a look at how Facebook solved two problems at once.</p><h3 name="1a05" id="1a05" class="graf graf--h3 graf-after--p">Problem Description</h3><p name="2f02" id="2f02" class="graf graf--p graf-after--h3">First, let me briefly explain the two problems.</p><p name="3518" id="3518" class="graf graf--p graf-after--p">In general, the behavior of a read-aside cache is to read from the cache first, and if it can’t be found, then read from the database instead. After retrieving data, write the data back to the cache. If the database is updated, the cached data is cleared without writing it back.</p><p name="a6cb" id="a6cb" class="graf graf--p graf-after--p">Even with this process, there are still problems, the most typical of which are the two problems mentioned in this article. The process of how stale sets occur is as follows.</p><figure name="3dfa" id="3dfa" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="0*XxQDJR6m2XMB7udx.png" data-width="1040" data-height="808" src="https://cdn-images-1.medium.com/max/800/0*XxQDJR6m2XMB7udx.png"></figure><p name="5f93" id="5f93" class="graf graf--p graf-after--figure">Although <code class="markup--code markup--p-code">B</code> has cleared the cache, <code class="markup--code markup--p-code">A</code> is delayed for “some reason”, so the data in the cache is written to the old data, which is the data stale or inconsistent.</p><p name="fa1a" id="fa1a" class="graf graf--p graf-after--p">On the other hand, when a cache miss occurs in a highly concurrent system, then all these clients will query the database, in other words, the database will fall down in a short time due to high concurrency. This problem is also known as the Dogpile effect.</p><h3 name="6a98" id="6a98" class="graf graf--h3 graf-after--p">Facebook’s solution</h3><p name="f03f" id="f03f" class="graf graf--p graf-after--h3">How did Facebook solve these two problems? They use a lease mechanism, which is described in section 3.2.1 of the paper, but the explanation is not very complete, it is roughly the following two paragraphs.</p><blockquote name="fc24" id="fc24" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">A memcached instance gives a lease to a<br>client to set data back into the cache when that client experiences a cache miss. Verification can fail if<br>memcached has invalidated the lease token due to receiving a delete request for that item.</em></blockquote><p name="4eda" id="4eda" class="graf graf--p graf-after--blockquote">And.</p><blockquote name="92c2" id="92c2" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">We configure these<br>servers to return a token only once every 10 seconds per<br>key.</em></blockquote><p name="de65" id="de65" class="graf graf--p graf-after--blockquote">When writing data to the cache, it must carry the token that was obtained during the cache miss. The cache will first validate the token before updating, and if the token validation fails, then it will be ignored. The token will be cleared when the database is updated.</p><p name="9434" id="9434" class="graf graf--p graf-after--p">Let’s explain this with the sequence diagram.</p><figure name="4037" id="4037" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*7OHj6rSIU9UxoqQM1w9HcA.png" data-width="1034" data-height="810" src="https://cdn-images-1.medium.com/max/800/1*7OHj6rSIU9UxoqQM1w9HcA.png"></figure><p name="2ed6" id="2ed6" class="graf graf--p graf-after--figure">The difference between this diagram and the problem one is the first interaction will get a token, when write cache need to carry the token, but because the token has been cleared after updating the database, so write cache will be rejected, this will solve the first problem.</p><p name="5cdd" id="5cdd" class="graf graf--p graf-after--p">As for the second problem is not difficult to deal with, just need to set the rules for the token release, every 10 seconds to send a token, if the client does not get the token then there is no authority to update the cache naturally there is no need to query the database, the Dogpile effect can be solved.</p><h3 name="2f51" id="2f51" class="graf graf--h3 graf-after--p">Simple implementation</h3><p name="86ea" id="86ea" class="graf graf--p graf-after--h3">To implement this logic is not so difficult, let’s use Python and Redis to write a simple example.</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="python" name="8d8f" id="8d8f" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Cache</span>:<br />    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br />        <span class="hljs-comment"># ignore implementation</span><br />    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get</span>(<span class="hljs-params">self, k</span>):<br />        v = self.redis.get(k)<br />        token = random.getrandbits(<span class="hljs-number">64</span>) <span class="hljs-comment"># Facebook says the token has to be 64 bit.</span><br />        ret = self.redis.<span class="hljs-built_in">set</span>(<span class="hljs-string">f&#x27;<span class="hljs-subst">{self.prefix}</span>#<span class="hljs-subst">{k}</span>&#x27;</span>, token, <span class="hljs-string">&#x27;NX&#x27;</span>, <span class="hljs-string">&#x27;EX&#x27;</span>, <span class="hljs-number">10</span>) <span class="hljs-comment"># 10s for token refresh</span><br />        <span class="hljs-keyword">return</span> (v, token <span class="hljs-keyword">if</span> ret == <span class="hljs-string">&#x27;OK&#x27;</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>)<br /><br />    <span class="hljs-keyword">def</span> <span class="hljs-title function_">set</span>(<span class="hljs-params">self, k, v, token</span>):<br />        saved_token = self.redis.get(<span class="hljs-string">f&#x27;<span class="hljs-subst">{self.prefix}</span>#<span class="hljs-subst">{k}</span>&#x27;</span>)<br />        <span class="hljs-keyword">if</span> token == saved_token:<br />            ret = self.redis.<span class="hljs-built_in">set</span>(k, v)<br />        <span class="hljs-keyword">else</span>:<br />            ret = <span class="hljs-literal">False</span><br />            <br />        <span class="hljs-keyword">return</span> ret == <span class="hljs-string">&#x27;OK&#x27;</span> <span class="hljs-keyword">or</span> <span class="hljs-literal">False</span><br />    <br />    <span class="hljs-keyword">def</span> <span class="hljs-title function_">clean</span>(<span class="hljs-params">self, k</span>):<br />        self.redis.<span class="hljs-keyword">del</span>(k, <span class="hljs-string">f&#x27;<span class="hljs-subst">{self.prefix}</span>#<span class="hljs-subst">{k}</span>&#x27;</span>)</span></pre><p name="026d" id="026d" class="graf graf--p graf-after--pre">To make it easier to understand, here we only show the core implementation and do not use Lua or other pipeline optimization methods.</p><p name="3b4d" id="3b4d" class="graf graf--p graf-after--p">In <code class="markup--code markup--p-code">get</code>, two values are returned, one is the result of the cache and the other is the token, if the original token still exists and has not expired, which means there is a possibility of thundering herds, then the token is not returned, and if the client does not receive the token, then he should not query the database.</p><p name="3e7e" id="3e7e" class="graf graf--p graf-after--p">In <code class="markup--code markup--p-code">set</code>, in addition to the key and value to write, we also need to carry the token, when the validation of the token fails, we don’t update the cache and just end it so as to avoid stale sets.</p><h3 name="5344" id="5344" class="graf graf--h3 graf-after--p">Conclusion</h3><p name="7606" id="7606" class="graf graf--p graf-after--h3">Stale sets and thundering herds are pretty common problems when using caches, and there are many solutions for them. But when I actually wrote the program based on Facebook’s solution, I realized that it can be so simple, which made me a bit surprised that we were “overthinking” before.</p><p name="b749" id="b749" class="graf graf--p graf-after--p graf--trailing">I believe that the simpler the solution, the better, and I will use Facebook’s solution to deal with the problem at hand in the future. In fact, there are many more methods and optimizations for dealing with caching at scale in this paper, making it a very worthwhile study.</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@lazypro" class="p-author h-card">Chunting Wu</a> on <a href="https://medium.com/p/28d52780fbca"><time class="dt-published" datetime="2023-10-23T02:19:13.141Z">October 23, 2023</time></a>.</p><p><a href="https://medium.com/@lazypro/handling-stale-sets-and-thundering-herds-of-cache-28d52780fbca" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on October 21, 2024.</p></footer></article></body></html>