<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Reducing Database Loading</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Reducing Database Loading</h1>
</header>
<section data-field="subtitle" class="p-summary">
Three approaches to improve database elasticity
</section>
<section data-field="body" class="e-content">
<section name="21ae" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="a4f5" id="a4f5" class="graf graf--h3 graf--leading graf--title">Reducing Database Loading</h3><h4 name="e6cd" id="e6cd" class="graf graf--h4 graf-after--h3 graf--subtitle">Three approaches to improve database elasticity</h4><figure name="36dc" id="36dc" class="graf graf--figure graf-after--h4"><img class="graf-image" data-image-id="0*6tX29iYZM7ndHxkx" data-width="1000" data-height="665" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/0*6tX29iYZM7ndHxkx"><figcaption class="imageCaption">Photo by <a href="https://unsplash.com/@mike_van_den_bos" data-href="https://unsplash.com/@mike_van_den_bos" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">Mike van den Bos</a> on <a href="https://unsplash.com/photos/jf1EomjlQi0" data-href="https://unsplash.com/photos/jf1EomjlQi0" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">Unsplash</a></figcaption></figure><p name="6318" id="6318" class="graf graf--p graf-after--figure">Last week we talked about <a href="https://betterprogramming.pub/scalability-vs-elasticity-cfae2d7a19b" data-href="https://betterprogramming.pub/scalability-vs-elasticity-cfae2d7a19b" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">the difference between scalability and elasticity</a>, and the concept of solutions was mentioned at a high level. In this article, let’s take a look at some practical solutions.</p><p name="c6b3" id="c6b3" class="graf graf--p graf-after--p">First, if you haven’t read <a href="https://betterprogramming.pub/scalability-vs-elasticity-cfae2d7a19b" data-href="https://betterprogramming.pub/scalability-vs-elasticity-cfae2d7a19b" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">the last article</a>, I suggest you read it first. This time we are solving the elasticity problem rather than scalability. As mentioned before, the two most common solutions to the elasticity problem are caching and messaging.</p><p name="e722" id="e722" class="graf graf--p graf-after--p">Therefore, in this article, we will list some common practical solutions and briefly analyze the advantages and disadvantages. Let’s get started.</p><h3 name="b4b1" id="b4b1" class="graf graf--h3 graf-after--p">Read-aside Cache</h3><p name="2321" id="2321" class="graf graf--p graf-after--h3">When talking about caching, the most commonly used mechanism is the read-aside cache.</p><p name="f1c1" id="f1c1" class="graf graf--p graf-after--p">The advantage is that it is very easy to understand and implement, and already provides a good consistency level. I’ve explained how it works in <a href="https://medium.com/starbugs/consistency-between-cache-and-database-part-1-f64f4a76720" data-href="https://medium.com/starbugs/consistency-between-cache-and-database-part-1-f64f4a76720" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">my previous article</a>, but let’s review it again.</p><figure name="2070" id="2070" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*NyvutdsOM3g_lZsTLQwufw.png" data-width="440" data-height="632" src="https://cdn-images-1.medium.com/max/800/1*NyvutdsOM3g_lZsTLQwufw.png"><figcaption class="imageCaption">Read Path of Read-aside Cache</figcaption></figure><p name="4cf4" id="4cf4" class="graf graf--p graf-after--figure">The read mechanism of the read-aside cache is very simple: first try to get the data from the cache, and if you cannot get it, then get it from the database instead, and save it back to the cache. In this way, the next request for the same data can be taken directly from the cache.</p><p name="c7bc" id="c7bc" class="graf graf--p graf-after--p">How to ensure that the cached data is up-to-date (consistency)?</p><figure name="dc14" id="dc14" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*uQumE0FrrikkRVczieqrjA.png" data-width="392" data-height="594" src="https://cdn-images-1.medium.com/max/800/1*uQumE0FrrikkRVczieqrjA.png"><figcaption class="imageCaption">Write Path of Read-aside Cache</figcaption></figure><p name="7f68" id="7f68" class="graf graf--p graf-after--figure">After updating the database, the corresponding records of the cache should be cleared immediately. When the same request comes in next time, it will be taken from the database first and the latest result will be written back to the cache.</p><p name="3a74" id="3a74" class="graf graf--p graf-after--p">It looks like both read and write are perfect, so the read-aside cache should have a high degree of consistency! In fact, not really.</p><figure name="0ef6" id="0ef6" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*v2lfsRIEgmJxRnKLcE9xAg.png" data-width="1038" data-height="588" src="https://cdn-images-1.medium.com/max/800/1*v2lfsRIEgmJxRnKLcE9xAg.png"><figcaption class="imageCaption">Problem #1 of Read-aside Cache</figcaption></figure><p name="c603" id="c603" class="graf graf--p graf-after--figure">According to the above sequential diagram, we can find that both A and B are behaving correctly, but put together, they make an error, and B gets inconsistent data. This is the first problem.</p><figure name="30bd" id="30bd" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*bMNgQafYbgkKtjBxiXCuxw.png" data-width="1000" data-height="636" src="https://cdn-images-1.medium.com/max/800/1*bMNgQafYbgkKtjBxiXCuxw.png"><figcaption class="imageCaption">Problem #2 of Read-aside Cache</figcaption></figure><p name="a3e6" id="a3e6" class="graf graf--p graf-after--figure">The second type of error is more intuitive, when A wants to update the data, A is killed after finishing the database update, probably due to bugs or application upgrade and so on. Then the data in the cache will remain inconsistent for a long time, until the next update or timeout.</p><figure name="08ae" id="08ae" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*gH283i-SpUYWimTznDnZag.png" data-width="1036" data-height="802" src="https://cdn-images-1.medium.com/max/800/1*gH283i-SpUYWimTznDnZag.png"><figcaption class="imageCaption">Problem #3 of Read-aside Cache</figcaption></figure><p name="99a3" id="99a3" class="graf graf--p graf-after--figure">The third error is similar to the first one in that the individual actions of A and B are correct, but put together they are wrong. This inconsistent cache data will also remain for a while until the next update.</p><p name="ca46" id="ca46" class="graf graf--p graf-after--p">These details have been explained in <a href="https://medium.com/starbugs/consistency-between-cache-and-database-part-1-f64f4a76720" data-href="https://medium.com/starbugs/consistency-between-cache-and-database-part-1-f64f4a76720" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">my previous article</a>, if you want to know more can also be used as a reference.</p><p name="993d" id="993d" class="graf graf--p graf-after--p">In fact, problems 1 and 3 can be greatly mitigated by modifying the implementation of the application. In the first problem, when A finished writing the data, don’t do anything else, then clean up the cache quickly to reduce the possibility of being touched by B.</p><p name="2552" id="2552" class="graf graf--p graf-after--p">The same is true for problem 3. When A finishes querying, don’t do too much processing and write back the cache as soon as possible, which can also greatly reduce the chance of occurring after B.</p><p name="de07" id="de07" class="graf graf--p graf-after--p">However, there are three potential problems with read-aside caching.</p><ol class="postList"><li name="ecd6" id="ecd6" class="graf graf--li graf-after--p">If a cache has a large scope of content, it can be difficult to determine when to clean it and to implement it. On the other hand, when many places have to be cleaned up, it may make the cache less effective.</li><li name="9da6" id="9da6" class="graf graf--li graf-after--li">Dog pile effect. This refers to when a high-traffic system accesses cache frequently, if it encounters clearing cache or cache expiration, these traffic will still occur on the database. And the database may not be able to hold up.</li><li name="7dd2" id="7dd2" class="graf graf--li graf-after--li">No graceful shutdown. Problems 1 and 3 can be improved by modifying the application, but problem 2 is not always possible, especially when the application fails, there is basically nothing to do.</li></ol><h3 name="01f6" id="01f6" class="graf graf--h3 graf-after--li">Denormalization</h3><blockquote name="f836" id="f836" class="graf graf--blockquote graf-after--h3"><em class="markup--em markup--blockquote-em">If we have to take data from many places, it is ideal to put it all together and take it only once.</em></blockquote><p name="794c" id="794c" class="graf graf--p graf-after--blockquote">Conventionally, in order to avoid data duplication in RDBMS, we would create individual tables according to the data type, and then join each other through foreign keys.</p><p name="3145" id="3145" class="graf graf--p graf-after--p">But this will cause a problem, if it is an aggregated data must be pulled from each table, in the traffic and data volume of the system is not large, this approach is reasonable, and will have good performance. However, in a big data scenario, such performance is tragic.</p><p name="d2ca" id="d2ca" class="graf graf--p graf-after--p">The performance of JOIN is not good enough for large data, and it is even worse if it is a subquery.</p><p name="a3d0" id="a3d0" class="graf graf--p graf-after--p">Therefore, the idea of denormalization is to put all the data together and pull all the required data through a single query. Common practices include Facts Tables, etc., but this article does not focus on data modeling, but on system architecture.</p><p name="ada7" id="ada7" class="graf graf--p graf-after--p">However, the problem is that reading from one place is possible, but what about writing to it? The original tables are already in use by clients, so do we need to find all the clients to modify them? No, it’s too much work!</p><p name="4a67" id="4a67" class="graf graf--p graf-after--p">There are two ways, synchronization and asynchronization.</p><figure name="405e" id="405e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*pcxw2zhD391pIZoNloTRBA.png" data-width="920" data-height="700" src="https://cdn-images-1.medium.com/max/800/1*pcxw2zhD391pIZoNloTRBA.png"><figcaption class="imageCaption">Synchronous Data Replication</figcaption></figure><p name="450a" id="450a" class="graf graf--p graf-after--figure">This is an architecture of synchronization. The following DBs can be treated as databases or tables or even caches.</p><p name="984b" id="984b" class="graf graf--p graf-after--p">When the service needs to write data, originally only <code class="markup--code markup--p-code">DB1</code>, <code class="markup--code markup--p-code">DB2</code> and <code class="markup--code markup--p-code">DB3</code> need to be written, in order to achieve denormalization, but also need to write <code class="markup--code markup--p-code">NewDB</code> in code, and <code class="markup--code markup--p-code">NewDB</code> is the result of aggregation.</p><p name="a512" id="a512" class="graf graf--p graf-after--p">If someone needs to aggregate results, they can pull them directly from <code class="markup--code markup--p-code">NewDB</code>. If the owners of these DBs all belong to the same functional team, then this implementation looks acceptable.</p><p name="2ee0" id="2ee0" class="graf graf--p graf-after--p">On the contrary, if the team that needs to consolidate the results is another functional team, such an architecture will not work. First, the other functional team has to find all the updates, then they have to make changes within the service, and they have to do it transactionally.</p><p name="f3aa" id="f3aa" class="graf graf--p graf-after--p">For a cross-functional team, such a workflow is unrealistic and impossible. Hence, asynchronous data replication is introduced.</p><figure name="f4fc" id="f4fc" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Jvc3ig-S14dPkr0FdlmgLQ.png" data-width="534" data-height="774" src="https://cdn-images-1.medium.com/max/800/1*Jvc3ig-S14dPkr0FdlmgLQ.png"><figcaption class="imageCaption">Asynchronous Data Replication</figcaption></figure><p name="3f38" id="3f38" class="graf graf--p graf-after--figure">This architecture should be very common in my previous articles, it is in fact CQRS.</p><ul class="postList"><li name="daa0" id="daa0" class="graf graf--li graf-after--p"><a href="https://medium.com/interviewnoodle/shift-from-monolith-to-cqrs-a34bab75617e" data-href="https://medium.com/interviewnoodle/shift-from-monolith-to-cqrs-a34bab75617e" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Shift from Monolith to CQRS</a></li><li name="c1f7" id="c1f7" class="graf graf--li graf-after--li"><a href="https://lazypro.medium.com/solve-performance-bottleneck-through-cqrs-3fd456df1551" data-href="https://lazypro.medium.com/solve-performance-bottleneck-through-cqrs-3fd456df1551" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Solve Performance Bottleneck through CQRS</a></li></ul><p name="9796" id="9796" class="graf graf--p graf-after--li">Nevertheless, there are various practices to implement CQRS, some of which are listed below. The following is a list of common practices from long to short time intervals.</p><p name="303e" id="303e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">ETL</em></strong></p><blockquote name="e6cb" id="e6cb" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">DBs -&gt; Batching -&gt; Materialized View</em></blockquote><p name="e1dc" id="e1dc" class="graf graf--p graf-after--blockquote">This is the most common practice nowadays, and almost all data engineers do it this way. Data is migrated from one place to another through batch processing, whether it is Hadoop or Spark.</p><p name="28b0" id="28b0" class="graf graf--p graf-after--p">Some transformations and business logic may be added in the process. In order to make the data more accessible, if RDBMS is used as the NewDB, then <code class="markup--code markup--p-code">Materialized View</code> may be added. The data is snapshotted by predefined rules, and if the data is updated, it is refreshed to respond to the calculation of new data.</p><p name="5c87" id="5c87" class="graf graf--p graf-after--p">But data migration is a very costly practice, so ETL does not happen all the time, instead, it happens once an hour or even once a day.</p><p name="99ee" id="99ee" class="graf graf--p graf-after--p">Therefore, the data obtained from NewDB will not be the latest, but a snapshot at a certain point in time.</p><p name="1a4e" id="1a4e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">CDC</em></strong></p><p name="99a6" id="99a6" class="graf graf--p graf-after--p">In order to keep the data as up-to-date as possible, we know that ETL is not enough. Therefore, CDC is another common practice.</p><blockquote name="1e80" id="1e80" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">DBs -&gt; Debezium -&gt; Kafka -&gt; Streaming DB</em></blockquote><p name="9d28" id="9d28" class="graf graf--p graf-after--blockquote">When data is updated, it is captured by <a href="https://debezium.io/" data-href="https://debezium.io/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Debezium</a>, streamed out to Kafka, and finally written to a streaming database.</p><p name="40c5" id="40c5" class="graf graf--p graf-after--p">The streaming database is made available to external users, so the streaming database must be able to support not only streaming writes, but also rapid query capabilities.</p><p name="6214" id="6214" class="graf graf--p graf-after--p">There are many mainstream streaming databases, and <a href="https://pinot.apache.org/" data-href="https://pinot.apache.org/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Apache Pinot</a> is the most popular one recently.</p><p name="4177" id="4177" class="graf graf--p graf-after--p">Because CDC streams are updated in real time, external users can get almost real-time data.</p><p name="3e23" id="3e23" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Streaming</em></strong></p><p name="e87c" id="e87c" class="graf graf--p graf-after--p">Another mechanism for real time streaming comes from the service that originally wrote the data.</p><blockquote name="e89a" id="e89a" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">Service -&gt; Kafka -&gt; Stream Handler -&gt; RocksDB</em></blockquote><p name="7cac" id="7cac" class="graf graf--p graf-after--blockquote">When the service finishes updating the original database, it actively sends an event to Kafka and Kafka dispatches it.</p><p name="b3c2" id="b3c2" class="graf graf--p graf-after--p">In such a system, it is most common to use a streaming framework to do the pre-processing of the streams and store them in the database. Common streaming frameworks include Apache Flink or Apache Samza, and of course the recent Kafka Stream.</p><p name="5da0" id="5da0" class="graf graf--p graf-after--p">For the backend database, we choose a state persistence mechanism that can match the streaming processing framework, and RocksDB is the best choice for several common streaming processing frameworks.</p><p name="2347" id="2347" class="graf graf--p graf-after--p graf--trailing">In this way, we can also get the latest data, but from the query point of view, the query capability provided by the streaming processing framework is not comparable to streaming database.</p></div></div></section><section name="441a" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="89ea" id="89ea" class="graf graf--p graf--leading">The above three are common data replication methods, and it is worth mentioning that the components of each method can be exchanged or even extended to each other, so that different architectures can be built based on requirements.</p><p name="96d2" id="96d2" class="graf graf--p graf-after--p">However, there are potential problems with asynchronous data replication.</p><ol class="postList"><li name="f97c" id="f97c" class="graf graf--li graf-after--p">If there is a wide range of data to be used, it is a big problem to define the data to be replicated. Just as it is difficult to determine the cleanup time for a read-aside cache, it is difficult to define the scope of data replication.</li><li name="da27" id="da27" class="graf graf--li graf-after--li">In addition, whether it is pre-processing through streaming framework or defining query through streaming database, the complexity is obviously high when it comes to complex data structure and complicated computation.</li><li name="ad8d" id="ad8d" class="graf graf--li graf-after--li">Among these three methods, ETL has the lowest complexity, but ETL loses data real-time.</li></ol><h3 name="f06a" id="f06a" class="graf graf--h3 graf-after--li">Asynchronous requests/responses</h3><p name="1f66" id="1f66" class="graf graf--p graf-after--h3">We all know the traditional request/response model as follows.</p><figure name="adf9" id="adf9" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*uGPTmseC78Rh1BdeSUuung.png" data-width="456" data-height="560" src="https://cdn-images-1.medium.com/max/800/1*uGPTmseC78Rh1BdeSUuung.png"><figcaption class="imageCaption">Synchronous Request Response Model</figcaption></figure><p name="d08e" id="d08e" class="graf graf--p graf-after--figure">Although this is a function call here, it can also be a remote call across services.</p><p name="beca" id="beca" class="graf graf--p graf-after--p">After the client sends a request, the server responds to the request through a series of processing, which is the traditional approach. How can we do this asynchronously?</p><figure name="38f4" id="38f4" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*7-XxlbHa-6YYAUrW07npRA.png" data-width="304" data-height="560" src="https://cdn-images-1.medium.com/max/800/1*7-XxlbHa-6YYAUrW07npRA.png"><figcaption class="imageCaption">Asynchronous Request Response Model</figcaption></figure><p name="06b7" id="06b7" class="graf graf--p graf-after--figure">The answer is to make the implementation of the function behind the server asynchronous.</p><p name="6643" id="6643" class="graf graf--p graf-after--p">What are the benefits of doing this?</p><ol class="postList"><li name="a965" id="a965" class="graf graf--li graf-after--p">Handle events by using event handlers, then we can control the number of handlers to determine the pressure on the backend system or database. In the synchronization model, when a large number of client requests come in, the server will fork threads accordingly and put pressure on the backend system. However, when the number of event handlers is controllable, the pressure on the backend system can be controlled as well.</li><li name="a3d5" id="a3d5" class="graf graf--li graf-after--li">Request dedup. Since all requests from clients are entered into the message queue, event handlers have the ability to perform deduplication according to specific rules.</li><li name="a45c" id="a45c" class="graf graf--li graf-after--li">Further, if a streaming framework is used, then the third approach from the previous section can be followed to achieve further denormalization.</li></ol><p name="6bb7" id="6bb7" class="graf graf--p graf-after--li">However, such an architecture also has drawbacks.</p><ol class="postList"><li name="6f7f" id="6f7f" class="graf graf--li graf-after--p">Such an architecture must be based on the assumption that users will refresh the page a lot in a short period of time in order to be able to play the benefits of dedup. This architecture does not mean that it is only applicable to this context, but if there is no matching context, then the implementation will be too much pain and too little gain.</li><li name="9162" id="9162" class="graf graf--li graf-after--li">Implementation overhead. The server must have the ability to wait for asynchronous messages, which is simple to say, but there are many aspects of the implementation. For example, should we use a temporary queue or a permanent queue? How long should I wait? Questions like these need to be carefully considered.</li><li name="4c1e" id="4c1e" class="graf graf--li graf-after--li">Starvation. In order to control the number of concurrent messages, we don’t enable handlers unlimitedly, but this also means that some people can’t wait for processing and time out.</li></ol><h3 name="46cd" id="46cd" class="graf graf--h3 graf-after--li">Conclusion</h3><p name="c070" id="c070" class="graf graf--p graf-after--h3">This article describes some approaches to improve the elasticity of a database.</p><p name="8f0c" id="8f0c" class="graf graf--p graf-after--p">Unlike the approaches to improve scalability, scalability can be achieved through database-oriented approaches such as query optimization, indexing, and data sharding.</p><p name="8716" id="8716" class="graf graf--p graf-after--p">However, improving elasticity cannot be accomplished through databases alone, but must be accompanied by architectural adjustments, so this article lists some common approaches.</p><p name="ac55" id="ac55" class="graf graf--p graf-after--p">In fact, there are many more useful practices than that, and this article is aimed at small to medium-sized organizations. With a limited number of people and a limited budget, it is not possible to make large-scale changes, so we can only optimize on the original practices.</p><p name="19b7" id="19b7" class="graf graf--p graf-after--p graf--trailing">Nevertheless, I believe these approaches should provide good insights for further evolution of the system, after all, all methodologies are similar.</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@lazypro" class="p-author h-card">Chunting Wu</a> on <a href="https://medium.com/p/b54f2d8edb39"><time class="dt-published" datetime="2022-09-12T01:37:46.566Z">September 12, 2022</time></a>.</p><p><a href="https://medium.com/@lazypro/reducing-database-loading-b54f2d8edb39" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on October 21, 2024.</p></footer></article></body></html>